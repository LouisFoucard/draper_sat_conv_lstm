{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import dicom, cv2, re, sys\n",
      "import os, fnmatch, shutil, subprocess\n",
      "import numpy as np\n",
      "from PIL import Image\n",
      "from IPython.utils import io\n",
      "import numpy as np\n",
      "np.random.seed(1234)\n",
      "import matplotlib as plt\n",
      "%matplotlib inline\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore') # we ignore a RuntimeWarning produced from dividing by zero\n",
      "import os, sys, urllib, gzip\n",
      "import cPickle as pickle\n",
      "sys.setrecursionlimit(10000)\n",
      "import glob\n",
      "from IPython.display import clear_output\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import numpy as np\n",
      "from IPython.display import Image as IPImage\n",
      "\n",
      "from PIL import Image\n",
      "from lasagne.layers import get_output, InputLayer, DenseLayer, Upscale2DLayer, ReshapeLayer\n",
      "from lasagne.init import GlorotUniform\n",
      "from lasagne.nonlinearities import rectify, leaky_rectify, tanh, sigmoid, softmax\n",
      "from lasagne.updates import nesterov_momentum, adam\n",
      "from lasagne.objectives import categorical_crossentropy, binary_crossentropy\n",
      "from nolearn.lasagne import NeuralNet, BatchIterator, PrintLayerInfo\n",
      "from lasagne.layers import Conv2DLayer as Conv2DLayer\n",
      "from lasagne.layers import MaxPool2DLayer as MaxPool2DLayer\n",
      "import theano \n",
      "import theano.tensor as T\n",
      "import lasagne\n",
      "import time\n",
      "try:\n",
      "    from lasagne.layers.dnn import Conv2DDNNLayer as Conv2DLayer\n",
      "    from lasagne.layers.dnn import Conv3DDNNLayer as Conv3DLayer\n",
      "    from lasagne.layers.dnn import MaxPool2DDNNLayer as MaxPool2DLayer\n",
      "    from lasagne.layers.dnn import MaxPool3DDNNLayer as MaxPool3DLayer\n",
      "    print 'Using cuda_convnet (faster)'\n",
      "except ImportError:\n",
      "    from lasagne.layers import Conv2DLayer as Conv2DLayer\n",
      "    from lasagne.layers import Conv3DLayer as Conv3DLayer\n",
      "    from lasagne.layers import Pool3Layer as Pool3Layer\n",
      "    from lasagne.layers import ReshapeLayer\n",
      "    print 'Using lasagne.layers (slower)'\n",
      "    \n",
      "import theano\n",
      "import theano.tensor as T\n",
      "\n",
      "from lasagne.layers import Layer\n",
      "from lasagne import init\n",
      "from lasagne import nonlinearities\n",
      "from scipy.misc import imresize, imread\n",
      "from PIL import ImageOps\n",
      "import scipy as sp\n",
      "import scipy.ndimage.morphology\n",
      "from skimage.morphology import convex_hull_image\n",
      "from skimage.restoration import denoise_tv_chambolle, denoise_bilateral\n",
      "import matplotlib.cm as cm\n",
      "from scipy.optimize import minimize\n",
      "from math import floor"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using cuda_convnet (faster)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using gpu device 0: GRID K520 (CNMeM is disabled)\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from batchNormalization import BatchNormLayer\n",
      "\n",
      "def batch_norm(layer, **kwargs):\n",
      "    nonlinearity = getattr(layer, 'nonlinearity', None)\n",
      "    if nonlinearity is not None:\n",
      "        layer.nonlinearity = nonlinearities.identity\n",
      "    if hasattr(layer, 'b') and layer.b is not None:\n",
      "        del layer.params[layer.b]\n",
      "        layer.b = None\n",
      "    layer = BatchNormLayer(layer, **kwargs)\n",
      "    if nonlinearity is not None:\n",
      "        from lasagne.layers import NonlinearityLayer\n",
      "        layer = NonlinearityLayer(layer, nonlinearity)\n",
      "    return layer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train = np.load(\"X_train_step12.npy\")\n",
      "y_train = np.load(\"y_train_step12.npy\")\n",
      "setNames_train = np.load(\"setNames_train_step12.npy\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "L,W,H = X_train.shape[1::]\n",
      "X_train = X_train.reshape(-1,1,L,W,H).astype(\"float32\")\n",
      "y_train = y_train.astype(\"float32\")\n",
      "print X_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(630, 1, 5, 225, 225)\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import lasagne\n",
      "from lasagne.layers.shape import PadLayer\n",
      "from lasagne.layers import InputLayer, DenseLayer, NonlinearityLayer\n",
      "from lasagne.layers.dnn import Conv3DDNNLayer, MaxPool3DDNNLayer\n",
      "from lasagne.nonlinearities import softmax\n",
      "\n",
      "import theano\n",
      "import numpy as np\n",
      "import skimage.transform\n",
      "from skimage import color\n",
      "import pickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gate_parameters = lasagne.layers.recurrent.Gate(\n",
      "    W_in=lasagne.init.Orthogonal(), W_hid=lasagne.init.Orthogonal(),\n",
      "    b=lasagne.init.Constant(0.))\n",
      "cell_parameters = lasagne.layers.recurrent.Gate(\n",
      "    W_in=lasagne.init.Orthogonal(), W_hid=lasagne.init.Orthogonal(),\n",
      "    # Setting W_cell to None denotes that no cell connection will be used.\n",
      "    W_cell=None, b=lasagne.init.Constant(0.),\n",
      "    # By convention, the cell nonlinearity is tanh in an LSTM.\n",
      "    nonlinearity=lasagne.nonlinearities.tanh)\n",
      "\n",
      "batch_size = 2\n",
      "\n",
      "def build_lstm_cnn(input_var=None):\n",
      "    \n",
      "    \n",
      "    conv_num_filters1 = 4\n",
      "    conv_num_filters2 = 8\n",
      "    conv_num_filters3 = 8\n",
      "    filter_size1 = 7\n",
      "    filter_size2 = 3\n",
      "    filter_size3 = 3\n",
      "    pool_size = 2\n",
      "    pool_size2 = 4\n",
      "    pad_in = 'valid'\n",
      "    pad_out = 'full'\n",
      "    \n",
      "    # Input layer, as usual:                                                                                                                                                                                \n",
      "    network = InputLayer(shape=(batch_size,1,L,W,H),input_var=input_var,name=\"input_layer\")                                                                                                                             \n",
      "    \n",
      "    network = Conv3DDNNLayer(network, conv_num_filters1, (1,filter_size1,filter_size1)\\\n",
      "                             , pad=1,nonlinearity=lasagne.nonlinearities.rectify,flip_filters=False, name = \"conv3_1\")\n",
      "    \n",
      "    network = MaxPool3DDNNLayer(network,pool_size=(1,pool_size,pool_size),stride=(1,pool_size,pool_size), name = \"pool3_1\")\n",
      "    \n",
      "    \n",
      "    network = Conv3DDNNLayer(network, conv_num_filters2, (1,filter_size2,filter_size2)\\\n",
      "                             , pad=1,nonlinearity=lasagne.nonlinearities.rectify,flip_filters=False, name = \"conv3_2\")\n",
      "    \n",
      "    network = MaxPool3DDNNLayer(network,pool_size=(1,pool_size,pool_size),stride=(1,pool_size,pool_size), name = \"pool3_2\")\n",
      "    \n",
      "    \n",
      "    network = Conv3DDNNLayer(network, conv_num_filters3, (1,filter_size3,filter_size3)\\\n",
      "                             , pad=1,nonlinearity=lasagne.nonlinearities.rectify,flip_filters=False, name = \"conv3_3\")\n",
      "    \n",
      "    network = MaxPool3DDNNLayer(network,pool_size=(1,pool_size,pool_size),stride=(1,pool_size,pool_size), name = \"pool3_3\")\n",
      "    \n",
      "    \n",
      "    Netshape = network.output_shape\n",
      "    \n",
      "    network = ReshapeLayer(network, shape = (-1,Netshape[2],Netshape[1],Netshape[3],Netshape[4]),name=\"reshape\")\n",
      "    \n",
      "    # Our LSTM will have 10 hidden/cell units\n",
      "    N_HIDDEN = 20\n",
      "    GRAD_CLIP = 100.0\n",
      "    network = lasagne.layers.recurrent.LSTMLayer(\n",
      "    network, N_HIDDEN, ingate=gate_parameters, forgetgate=gate_parameters,\n",
      "     cell=cell_parameters, outgate=gate_parameters,\n",
      "    grad_clipping=GRAD_CLIP,\n",
      "    learn_init=True,name=\"lstm_1\")\n",
      "\n",
      "    network = lasagne.layers.recurrent.LSTMLayer(\n",
      "    network, N_HIDDEN, ingate=gate_parameters, forgetgate=gate_parameters,\n",
      "     cell=cell_parameters, outgate=gate_parameters,\n",
      "    grad_clipping=GRAD_CLIP,\n",
      "    learn_init=True,name = \"lstm_2\")\n",
      "\n",
      "    network = lasagne.layers.SliceLayer(network, -1, 1,name=\"slice\")\n",
      "    \n",
      "    network = batch_norm(lasagne.layers.DenseLayer(network, num_units=1, \\\n",
      "                                  W = lasagne.init.Normal(), \\\n",
      "                                  nonlinearity=lasagne.nonlinearities.softmax,name = \"dense\"))\n",
      "    \n",
      "    return network\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "network = build_lstm_cnn()\n",
      "\n",
      "laylist = lasagne.layers.get_all_layers(network)\n",
      "for l in laylist:\n",
      "    print(l.name, lasagne.layers.get_output_shape(l))\n",
      "\n",
      "num_params = lasagne.layers.count_params(network)\n",
      "print(\"# of parameters is {}\".format(num_params))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('input_layer', (2, 1, 5, 225, 225))\n",
        "('conv3_1', (2, 4, 7, 221, 221))\n",
        "('pool3_1', (2, 4, 7, 110, 110))\n",
        "('conv3_2', (2, 8, 9, 110, 110))\n",
        "('pool3_2', (2, 8, 9, 55, 55))\n",
        "('conv3_3', (2, 8, 11, 55, 55))\n",
        "('pool3_3', (2, 8, 11, 27, 27))\n",
        "('reshape', (2, 11, 8, 27, 27))\n",
        "('lstm_1', (2, 11, 20))\n",
        "('lstm_2', (2, 11, 20))\n",
        "('slice', (2, 20))\n",
        "('dense', (2, 1))\n",
        "(None, (2, 1))\n",
        "(None, (2, 1))\n",
        "# of parameters is 472824\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}